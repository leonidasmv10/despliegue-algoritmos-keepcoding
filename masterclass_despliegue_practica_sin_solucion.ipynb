{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Práctica Final: Clasificación con Scikit-learn y MLflow\n",
        "\n",
        "En esta práctica, utilizarás un conjunto de datos de Scikit-learn (podeís usar el mismo que en el notebook de Intro MLFlow) para entrenar un modelo de clasificación.\n",
        "\n",
        "Pasos a seguir: \n",
        "\n",
        "    Exploración de Datos: Analiza el conjunto de datos proporcionado para comprender su estructura y contenido.\n",
        "\n",
        "    Preprocesamiento de Texto: Realiza tareas de preprocesamiento de texto, como tokenización y vectorización, para preparar los datos para el modelado.\n",
        "\n",
        "    Entrenamiento del Modelo: Utiliza algoritmos de clasificación de Scikit-learn para entrenar un modelo con los datos preprocesados.\n",
        "\n",
        "    Evaluación del Modelo: Evalúa el rendimiento del modelo utilizando métricas de evaluación estándar como precisión y recall.\n",
        "\n",
        "    Registro de Métricas con MLflow: Utiliza MLflow para registrar métricas y hiperparámetros durante el entrenamiento, facilitando la gestión y comparación de experimentos.\n",
        "\n",
        "\n",
        "Nota: Dado que no voy a poder tener acceso a vuestros logs de MLFlow añadirme las imagenes de la interfaz de MLFlow en el notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🧠 Clasificador de texto\n",
        "🔍 ¿Qué hace este clasificador?\n",
        "Este clasificador tiene como objetivo:\n",
        "\n",
        "Predecir la categoría o clase de un texto, basándose en patrones aprendidos durante el entrenamiento.\n",
        "\n",
        "En este caso, ha sido entrenado con textos pertenecientes a diferentes temas (como religión, ciencia médica, computación gráfica o el espacio), por lo que puede identificar automáticamente a qué categoría pertenece un nuevo texto, dependiendo del modelo que se escoja y la categoría usada durante el entrenamiento.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Init](screenshots/log-init.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Init](screenshots/log.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Init](screenshots/comparation-8v.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Init](screenshots/models.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Init](screenshots/model_versions.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Init](screenshots/comparation_versions.png)\n",
        "Podemos que ver la versión 3 es la que mejor precisión tiene, si en caso necestaramos usarlo en producción usaria: model_uri = f\"models:/{model_name}/3\" "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Init](screenshots/comparation_version_visual.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generar .py de funciones y main con al menos dos argumentos de entrada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import argparse\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_metrics(y_true, y_pred):\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"precision\": precision_score(y_true, y_pred),\n",
        "        \"recall\": recall_score(y_true, y_pred),\n",
        "        \"f1_score\": f1_score(y_true, y_pred),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_pipeline(\n",
        "    max_iter=100,\n",
        "    C=1.0,\n",
        "    max_features=None,\n",
        "    ngram_max=1,\n",
        "):\n",
        "    pipeline = Pipeline(\n",
        "        [\n",
        "            (\n",
        "                \"vectorizer\",\n",
        "                TfidfVectorizer(\n",
        "                    max_features=max_features,\n",
        "                    ngram_range=(1, ngram_max),\n",
        "                ),\n",
        "            ),\n",
        "            (\n",
        "                \"clf\",\n",
        "                LogisticRegression(\n",
        "                    max_iter=max_iter,\n",
        "                    C=C,\n",
        "                ),\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "    return pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sanitize_name(name):\n",
        "    return name.replace(\".\", \"_\").replace(\"/\", \"_\").replace(\" \", \"_\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main(\n",
        "    categoria1,\n",
        "    categoria2,\n",
        "    max_iter,\n",
        "    C,\n",
        "    max_features,\n",
        "    ngram_max,\n",
        "):\n",
        "    data = fetch_20newsgroups(\n",
        "        subset=\"all\",\n",
        "        categories=[categoria1, categoria2],\n",
        "        remove=(\"headers\", \"footers\", \"quotes\"),\n",
        "    )\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        data.data, data.target, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    pipeline = create_pipeline(\n",
        "        max_iter=max_iter,\n",
        "        C=C,\n",
        "        max_features=max_features,\n",
        "        ngram_max=ngram_max,\n",
        "    )\n",
        "\n",
        "    mlflow.set_experiment(\"text_classification\")\n",
        "    with mlflow.start_run(run_name=f\"{categoria1}_vs_{categoria2}\"):\n",
        "        pipeline.fit(X_train, y_train)\n",
        "        y_pred = pipeline.predict(X_test)\n",
        "\n",
        "        metricas = calculate_metrics(y_test, y_pred)\n",
        "        for clave, valor in metricas.items():\n",
        "            mlflow.log_metric(clave, valor)\n",
        "\n",
        "        # Loguear hiperparámetros\n",
        "        mlflow.log_param(\"max_iter\", max_iter)\n",
        "        mlflow.log_param(\"C\", C)\n",
        "        mlflow.log_param(\"max_features\", max_features)\n",
        "        mlflow.log_param(\"ngram_max\", ngram_max)\n",
        "\n",
        "        mlflow.log_param(\"modelo\", f\"LogisticRegression_{categoria1}_vs_{categoria2}\")\n",
        "        mlflow.log_param(\"vectorizer\", f\"TfidfVectorizer_{categoria1}_vs_{categoria2}\")\n",
        "\n",
        "        modelo_name = f\"modelo_texto_{categoria1}_vs_{categoria2}\"\n",
        "        modelo_name = sanitize_name(modelo_name)\n",
        "\n",
        "        registered_name = f\"TextoClasificador_{categoria1}_vs_{categoria2}\"\n",
        "        registered_name = sanitize_name(registered_name)\n",
        "\n",
        "        mlflow.sklearn.log_model(\n",
        "            pipeline, modelo_name, registered_model_name=registered_name\n",
        "        )\n",
        "\n",
        "        print(f\"\\nResultado entre '{categoria1}' y '{categoria2}':\")\n",
        "        for k, v in metricas.items():\n",
        "            print(f\"{k}: {v:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\n",
        "        \"--categoria1\",\n",
        "        required=True,\n",
        "        help=\"Nombre de la primera categoría (ej: 'sci.space')\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--categoria2\",\n",
        "        required=True,\n",
        "        help=\"Nombre de la segunda categoría (ej: 'comp.graphics')\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--max_iter\",\n",
        "        type=int,\n",
        "        default=100,\n",
        "        help=\"Número máximo de iteraciones para LogisticRegression\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--C\",\n",
        "        type=float,\n",
        "        default=1.0,\n",
        "        help=\"Parámetro de regularización para LogisticRegression\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--max_features\",\n",
        "        type=int,\n",
        "        default=None,\n",
        "        help=\"Máximo número de características para TfidfVectorizer\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--ngram_max\", type=int, default=1, help=\"Máximo ngram para TfidfVectorizer\"\n",
        "    )\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    main(\n",
        "        args.categoria1,\n",
        "        args.categoria2,\n",
        "        args.max_iter,\n",
        "        args.C,\n",
        "        args.max_features,\n",
        "        args.ngram_max,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comando para desplegar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Resultado entre 'sci.space' y 'comp.graphics':\n",
            "accuracy: 0.898\n",
            "precision: 0.917\n",
            "recall: 0.880\n",
            "f1_score: 0.898\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/15 18:07:48 INFO mlflow.tracking.fluent: Experiment with name 'text_classification' does not exist. Creating a new experiment.\n",
            "2025/06/15 18:07:52 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/06/15 18:08:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "Successfully registered model 'TextoClasificador_sci_space_vs_comp_graphics'.\n",
            "Created version '1' of model 'TextoClasificador_sci_space_vs_comp_graphics'.\n"
          ]
        }
      ],
      "source": [
        "!py mlflow_load.py --categoria1 sci.space --categoria2 comp.graphics --max_iter 200 --C 0.5 --max_features 10000 --ngram_max 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comando para realizar predicción"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Texto: NASA launched a new satellite this month\n",
            "Predicción (label numérico): 1\n",
            "Categoría predicha: sci.space\n"
          ]
        }
      ],
      "source": [
        "!py mlflow_predict.py \"NASA launched a new satellite this month\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Práctica parte FastAPI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Para esta parte de la práctica teneis que generar un script con al menos 5 modulos app.get y dos de ellos tienen que ser pipelines de HF. \n",
        "\n",
        "### Parte de la practica se tendra que entregar en capturas de pantalla. Las capturas de pantalla a adjuntas son las siguientes. \n",
        "\n",
        "### 1. Captura de la pantalla docs con al menos 5 modulos. \n",
        "### 2. Captura de cada una de los modulos con la respuesta dentro de docs. \n",
        "### 3. Captura de cada uno de los modulos en la llamada https.\n",
        "### 4. Todo el codigo usado durante el proceso. Notebooks y scripts.\n",
        "\n",
        "### Opcional\n",
        "\n",
        "### 5. Despliegue del script en GCP Cloud Run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Init](screenshots/api.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Init](screenshots/root.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Init](screenshots/greet.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Init](screenshots/double.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analizador de sentimientos (HugginFace)\n",
        "![Init](screenshots/sentyments.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Traducir texto de Inglés a Frances (HugginFace)\n",
        "![Init](screenshots/translate.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generación de imagenes (HugginFace)\n",
        "![Init](screenshots/generate_image.png)\n",
        "![Init](screenshots/image_base64.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extraer embedding de un texto (HugginFace)\n",
        "![Init](screenshots/embed.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predecir categoria (space o computer graphics) de texto de la práctica MLFLOW\n",
        "![Init](screenshots/predict_text_category.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "!uvicorn api_fast:app --reload"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Código completo aquí o api_fast.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from fastapi import FastAPI\n",
        "from transformers import pipeline, AutoTokenizer, AutoModel\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "import base64\n",
        "from io import BytesIO\n",
        "import mlflow\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "app = FastAPI(title=\"API\")\n",
        "\n",
        "# === MODELOS DE TRANSFORMERS ===\n",
        "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
        "translator = pipeline(\"translation_en_to_fr\")\n",
        "\n",
        "# === MODELO DE EMBEDDINGS ===\n",
        "tokenizer_embed = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-Embedding-0.6B\")\n",
        "model_embed = AutoModel.from_pretrained(\"Qwen/Qwen3-Embedding-0.6B\")\n",
        "\n",
        "# === MODELO DE IMAGEN (Stable Diffusion) ===\n",
        "dreamlike_pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    \"dreamlike-art/dreamlike-anime-1.0\", torch_dtype=torch.float16, use_safetensors=True\n",
        ").to(\"cuda\")\n",
        "\n",
        "\n",
        "@app.get(\"/\")\n",
        "def read_root():\n",
        "    return {\"message\": \"Welcome to the AI API!\"}\n",
        "\n",
        "\n",
        "@app.get(\"/greet\")\n",
        "def greet(name: str = \"user\"):\n",
        "    return {\"message\": f\"Hello, {name}!\"}\n",
        "\n",
        "\n",
        "@app.get(\"/double\")\n",
        "def double(number: int):\n",
        "    return {\"result\": number * 2}\n",
        "\n",
        "\n",
        "@app.get(\"/sentiment_analysis\")\n",
        "def sentiment_analysis(text: str):\n",
        "    result = sentiment_analyzer(text)\n",
        "    return {\"sentiment\": result}\n",
        "\n",
        "\n",
        "@app.get(\"/translate\")\n",
        "def translate(text: str):\n",
        "    result = translator(text)\n",
        "    return {\"translation\": result[0][\"translation_text\"]}\n",
        "\n",
        "\n",
        "@app.get(\"/generate_image\")\n",
        "def generate_image(prompt: str = \"an anime girl in a magical forest\"):\n",
        "    image = dreamlike_pipe(prompt).images[0]\n",
        "\n",
        "    buffer = BytesIO()\n",
        "    image.save(buffer, format=\"PNG\")\n",
        "    img_base64 = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
        "\n",
        "    return {\"prompt\": prompt, \"image_base64\": img_base64}\n",
        "\n",
        "\n",
        "@app.get(\"/embed_text\")\n",
        "def embed_text(text: str):\n",
        "    inputs = tokenizer_embed(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model_embed(**inputs)\n",
        "        embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
        "    return {\"text\": text, \"embedding\": embeddings[0].tolist()}\n",
        "\n",
        "\n",
        "# === FUNCIONES MLflow ===\n",
        "\n",
        "\n",
        "def sanitize_name(name):\n",
        "    return name.replace(\".\", \"_\").replace(\"/\", \"_\").replace(\" \", \"_\")\n",
        "\n",
        "\n",
        "@app.get(\"/predict_text_category\")\n",
        "def predict_text_category(text: str = \"NASA launched a new satellite this month\"):\n",
        "    # Define categorías\n",
        "    categoria1 = \"sci.space\"\n",
        "    categoria2 = \"comp.graphics\"\n",
        "    categorias = [categoria1, categoria2]\n",
        "\n",
        "    # Obtener los nombres de clases\n",
        "    target_names = fetch_20newsgroups(\n",
        "        subset=\"train\", categories=categorias\n",
        "    ).target_names\n",
        "\n",
        "    # Modelo en MLflow\n",
        "    model_name = f\"TextoClasificador_{categoria1}_vs_{categoria2}\"\n",
        "    model_name = sanitize_name(model_name)\n",
        "    model_uri = f\"models:/{model_name}/latest\"\n",
        "\n",
        "    try:\n",
        "        model = mlflow.pyfunc.load_model(model_uri)\n",
        "        prediccion = model.predict([text])\n",
        "        clase_predicha = target_names[prediccion[0]]\n",
        "\n",
        "        return {\n",
        "            \"text\": text,\n",
        "            \"predicted_label\": int(prediccion[0]),\n",
        "            \"predicted_category\": clase_predicha,\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
